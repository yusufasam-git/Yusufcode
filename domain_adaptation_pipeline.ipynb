{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yusufasam-git/Yusufcode/blob/main/domain_adaptation_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahVPc2aj7U10"
      },
      "source": [
        "# A Clean, General Domain Adaptation Pipeline (DANN-style)\n",
        "\n",
        "This notebook implements a **minimal, general domain adaptation pipeline** using a simple synthetic dataset.\n",
        "\n",
        "Core ideas:\n",
        "- A **source domain** with labels\n",
        "- A **target domain** without labels (used only for domain alignment)\n",
        "- A model with:\n",
        "  - **Feature extractor**\n",
        "  - **Label classifier**\n",
        "  - **Domain discriminator**\n",
        "- A **DANN-style loss**: classification on source + adversarial domain loss on source+target\n",
        "\n",
        "You can later swap the synthetic data with real datasets and keep the same pipeline."
      ],
      "id": "ahVPc2aj7U10"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2SqU2pp7U11"
      },
      "source": [
        "## 1. Install and import dependencies"
      ],
      "id": "b2SqU2pp7U11"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DprlMkVq7U12"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision matplotlib scikit-learn --quiet"
      ],
      "id": "DprlMkVq7U12"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gveDtwpM7U12"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "id": "gveDtwpM7U12"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D74KgMb7U12"
      },
      "source": [
        "## 2. Create synthetic source and target domains\n",
        "\n",
        "- **Source domain**: standard two-moons dataset\n",
        "- **Target domain**: shifted and rotated version of the same data (domain shift)\n",
        "\n",
        "Source has labels, target is treated as unlabeled (for adaptation)."
      ],
      "id": "5D74KgMb7U12"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HchmHxb77U12"
      },
      "outputs": [],
      "source": [
        "def create_synthetic_domains(n_samples=2000, noise=0.1, shift=(1.0, 0.5)):\n",
        "    # Source: two moons\n",
        "    Xs, ys = make_moons(n_samples=n_samples, noise=noise, random_state=0)\n",
        "\n",
        "    # Target: same moons but shifted and rotated (domain shift)\n",
        "    Xt, yt = make_moons(n_samples=n_samples, noise=noise, random_state=1)\n",
        "\n",
        "    # Apply a simple transform to create domain shift\n",
        "    theta = np.radians(25)\n",
        "    R = np.array([[np.cos(theta), -np.sin(theta)],\n",
        "                  [np.sin(theta),  np.cos(theta)]])\n",
        "    Xt = Xt @ R.T\n",
        "    Xt = Xt + np.array(shift)\n",
        "\n",
        "    return Xs.astype(np.float32), ys.astype(np.int64), Xt.astype(np.float32), yt.astype(np.int64)\n",
        "\n",
        "Xs, ys, Xt, yt = create_synthetic_domains()\n",
        "\n",
        "print(\"Source shape:\", Xs.shape, ys.shape)\n",
        "print(\"Target shape:\", Xt.shape, yt.shape)"
      ],
      "id": "HchmHxb77U12"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BUiHzWn7U13"
      },
      "source": [
        "### Visualize the two domains (before adaptation)"
      ],
      "id": "6BUiHzWn7U13"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYFbzSu47U13"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(Xs[:, 0], Xs[:, 1], c=ys, cmap='coolwarm', alpha=0.6, label='Source')\n",
        "plt.scatter(Xt[:, 0], Xt[:, 1], c=yt, cmap='coolwarm', alpha=0.2, marker='x', label='Target')\n",
        "plt.title(\"Source vs Target domains (input space)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "aYFbzSu47U13"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKWU_E3Y7U13"
      },
      "source": [
        "## 3. Create PyTorch datasets and dataloaders\n",
        "\n",
        "- Source dataset: features + labels\n",
        "- Target dataset: features only (labels not used for training in unsupervised DA)\n",
        "- We'll still keep target labels separately for **evaluation** purposes."
      ],
      "id": "LKWU_E3Y7U13"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2c0WAFF7U13"
      },
      "outputs": [],
      "source": [
        "class SourceDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.from_numpy(X)\n",
        "        self.y = torch.from_numpy(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "class TargetDataset(Dataset):\n",
        "    def __init__(self, X):\n",
        "        self.X = torch.from_numpy(X)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx]\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "source_dataset = SourceDataset(Xs, ys)\n",
        "target_dataset = TargetDataset(Xt)\n",
        "\n",
        "source_loader = DataLoader(source_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "target_loader = DataLoader(target_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "print(\"Source batches:\", len(source_loader))\n",
        "print(\"Target batches:\", len(target_loader))"
      ],
      "id": "B2c0WAFF7U13"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUV6s1pm7U14"
      },
      "source": [
        "## 4. Define the model components\n",
        "\n",
        "We build three modules:\n",
        "\n",
        "- **FeatureExtractor**: maps 2D input to a higher-dimensional feature space\n",
        "- **LabelClassifier**: predicts class labels from features\n",
        "- **DomainDiscriminator**: predicts whether features come from source or target\n",
        "\n",
        "We also implement a simple **Gradient Reversal Layer (GRL)** for adversarial training (DANN)."
      ],
      "id": "xUV6s1pm7U14"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gDY4cOe7U14"
      },
      "outputs": [],
      "source": [
        "class GradientReversalFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, lambda_):\n",
        "        ctx.lambda_ = lambda_\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return -ctx.lambda_ * grad_output, None\n",
        "\n",
        "class GradientReversalLayer(nn.Module):\n",
        "    def __init__(self, lambda_=1.0):\n",
        "        super().__init__()\n",
        "        self.lambda_ = lambda_\n",
        "\n",
        "    def forward(self, x):\n",
        "        return GradientReversalFunction.apply(x, self.lambda_)\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, input_dim=2, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class LabelClassifier(nn.Module):\n",
        "    def __init__(self, feature_dim=64, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(feature_dim, feature_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feature_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, f):\n",
        "        return self.net(f)\n",
        "\n",
        "class DomainDiscriminator(nn.Module):\n",
        "    def __init__(self, feature_dim=64, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(feature_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, f):\n",
        "        return self.net(f)\n",
        "\n",
        "feature_extractor = FeatureExtractor().to(device)\n",
        "label_classifier = LabelClassifier().to(device)\n",
        "domain_discriminator = DomainDiscriminator().to(device)\n",
        "\n",
        "print(feature_extractor)\n",
        "print(label_classifier)\n",
        "print(domain_discriminator)"
      ],
      "id": "5gDY4cOe7U14"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GEXwtVP7U14"
      },
      "source": [
        "## 5. Define training utilities\n",
        "\n",
        "We will optimize:\n",
        "\n",
        "- **Classification loss** on source: cross entropy\n",
        "- **Domain loss** on source+target: binary cross entropy\n",
        "\n",
        "Total loss:\n",
        "\\begin{equation}\n",
        "L = L_{cls}(x_s, y_s) + \\lambda \\cdot L_{adv}(x_s, x_t)\n",
        "\\end{equation}\n",
        "\n",
        "Where \\(\\lambda\\) controls the strength of domain alignment."
      ],
      "id": "7GEXwtVP7U14"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNklA3gV7U14"
      },
      "outputs": [],
      "source": [
        "cls_criterion = nn.CrossEntropyLoss()\n",
        "dom_criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "params = list(feature_extractor.parameters()) + list(label_classifier.parameters()) + list(domain_discriminator.parameters())\n",
        "optimizer = optim.Adam(params, lr=1e-3)\n",
        "\n",
        "grl = GradientReversalLayer(lambda_=1.0)\n",
        "\n",
        "lambda_domain = 0.5  # weight of domain loss\n",
        "num_epochs = 50"
      ],
      "id": "CNklA3gV7U14"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZYsy5cy7U14"
      },
      "source": [
        "## 6. Training loop (DANN-style)\n",
        "\n",
        "At each step:\n",
        "\n",
        "1. Sample a batch from **source**: \\(x_s, y_s\\)\n",
        "2. Sample a batch from **target**: \\(x_t\\)\n",
        "3. Compute source features, classification predictions\n",
        "4. Compute domain predictions (source vs target) using features passed through GRL\n",
        "5. Backpropagate the combined loss and update all networks."
      ],
      "id": "2ZYsy5cy7U14"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKCDg_cV7U14"
      },
      "outputs": [],
      "source": [
        "def train_epoch(epoch, source_loader, target_loader):\n",
        "    feature_extractor.train()\n",
        "    label_classifier.train()\n",
        "    domain_discriminator.train()\n",
        "\n",
        "    total_cls_loss = 0.0\n",
        "    total_dom_loss = 0.0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    target_iter = iter(target_loader)\n",
        "\n",
        "    for i, (xs, ys_batch) in enumerate(source_loader):\n",
        "        try:\n",
        "            xt = next(target_iter)\n",
        "        except StopIteration:\n",
        "            target_iter = iter(target_loader)\n",
        "            xt = next(target_iter)\n",
        "\n",
        "        xs = xs.to(device)\n",
        "        ys_batch = ys_batch.to(device)\n",
        "        xt = xt.to(device)\n",
        "\n",
        "        # --------------------\n",
        "        # 1. Label prediction on source\n",
        "        # --------------------\n",
        "        fs = feature_extractor(xs)\n",
        "        logits_cls = label_classifier(fs)\n",
        "        loss_cls = cls_criterion(logits_cls, ys_batch)\n",
        "\n",
        "        # --------------------\n",
        "        # 2. Domain prediction (source + target)\n",
        "        # --------------------\n",
        "        ft = feature_extractor(xt)\n",
        "\n",
        "        f_concat = torch.cat([fs, ft], dim=0)\n",
        "        f_rev = grl(f_concat)  # gradient reversal\n",
        "\n",
        "        dom_logits = domain_discriminator(f_rev).view(-1)\n",
        "\n",
        "        dom_labels = torch.cat([\n",
        "            torch.ones(fs.size(0), device=device),   # source = 1\n",
        "            torch.zeros(ft.size(0), device=device)   # target = 0\n",
        "        ], dim=0)\n",
        "\n",
        "        loss_dom = dom_criterion(dom_logits, dom_labels)\n",
        "\n",
        "        # --------------------\n",
        "        # 3. Total loss\n",
        "        # --------------------\n",
        "        loss = loss_cls + lambda_domain * loss_dom\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_cls_loss += loss_cls.item()\n",
        "        total_dom_loss += loss_dom.item()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    n_batches = len(source_loader)\n",
        "    print(f\"Epoch {epoch+1}: cls_loss={total_cls_loss/n_batches:.4f}, dom_loss={total_dom_loss/n_batches:.4f}, total={total_loss/n_batches:.4f}\")\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_epoch(epoch, source_loader, target_loader)"
      ],
      "id": "dKCDg_cV7U14"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvqFOwhG7U15"
      },
      "source": [
        "## 7. Evaluation on target domain (classification accuracy)\n",
        "\n",
        "Here we **pretend** we don't have target labels during training (unsupervised DA),\n",
        "but we now use them to evaluate how well adaptation worked.\n",
        "\n",
        "We compare:\n",
        "- A classifier trained only on source (no DA) – for this simple notebook we mainly see final performance\n",
        "- The DANN-style adapted model."
      ],
      "id": "ZvqFOwhG7U15"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPw4Au-e7U15"
      },
      "outputs": [],
      "source": [
        "def evaluate_on_target(Xt, yt):\n",
        "    feature_extractor.eval()\n",
        "    label_classifier.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        X_tensor = torch.from_numpy(Xt).to(device)\n",
        "        y_true = torch.from_numpy(yt).to(device)\n",
        "\n",
        "        features = feature_extractor(X_tensor)\n",
        "        logits = label_classifier(features)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        acc = (preds == y_true).float().mean().item()\n",
        "\n",
        "    return acc\n",
        "\n",
        "target_acc = evaluate_on_target(Xt, yt)\n",
        "print(f\"Target domain accuracy after adaptation: {target_acc*100:.2f}%\")"
      ],
      "id": "sPw4Au-e7U15"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vHGVMlb7U15"
      },
      "source": [
        "## 8. Visualize feature space with t-SNE\n",
        "\n",
        "We project the features into 2D using t-SNE to see:\n",
        "- How **source vs target** distributions overlap\n",
        "- Whether classes separate better across domains after adaptation."
      ],
      "id": "2vHGVMlb7U15"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeNR7ixn7U15"
      },
      "outputs": [],
      "source": [
        "def extract_features(X, domain_label):\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        X_tensor = torch.from_numpy(X).to(device)\n",
        "        f = feature_extractor(X_tensor)\n",
        "    return f.cpu().numpy(), np.full(len(X), domain_label)\n",
        "\n",
        "# Sample subset for visualization\n",
        "idx_s = np.random.choice(len(Xs), size=500, replace=False)\n",
        "idx_t = np.random.choice(len(Xt), size=500, replace=False)\n",
        "\n",
        "Fs, dom_s = extract_features(Xs[idx_s], domain_label=0)  # 0 = source\n",
        "Ft, dom_t = extract_features(Xt[idx_t], domain_label=1)  # 1 = target\n",
        "\n",
        "F_all = np.concatenate([Fs, Ft], axis=0)\n",
        "dom_all = np.concatenate([dom_s, dom_t], axis=0)\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "F_2d = tsne.fit_transform(F_all)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(F_2d[dom_all == 0, 0], F_2d[dom_all == 0, 1], alpha=0.6, label='Source features')\n",
        "plt.scatter(F_2d[dom_all == 1, 0], F_2d[dom_all == 1, 1], alpha=0.6, label='Target features')\n",
        "plt.title(\"t-SNE of learned features (after DA)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "jeNR7ixn7U15"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrLkvL907U16"
      },
      "source": [
        "## 9. How to extend this pipeline\n",
        "\n",
        "This notebook is intentionally **simple and generic**. To use it in real projects:\n",
        "\n",
        "1. **Replace the synthetic data** with real datasets (e.g., Office-31, digits, VisDA, medical).\n",
        "2. Move the model classes (FeatureExtractor, LabelClassifier, DomainDiscriminator) into a `models/` folder.\n",
        "3. Move the training loop into a `trainer_dann.py` file.\n",
        "4. Use a `configs/` folder with YAML files to define hyperparameters.\n",
        "5. Log results (loss, accuracy) to TensorBoard or CSV.\n",
        "\n",
        "The core ideas — source loader, target loader, feature extractor, classifier, domain discriminator, and losses — remain exactly the same."
      ],
      "id": "KrLkvL907U16"
    }
  ]
}